{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pet Tracker Data Analysis\n",
    "Analysis of tag location data stored in Parquet format using DuckDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import duckdb\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "# Set style for better visualizations\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Initialize DuckDB connection\n",
    "conn = duckdb.connect()\n",
    "print(f\"DuckDB version: {duckdb.__version__}\")\n",
    "print(f\"Current directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check directory structure\n",
    "import glob\n",
    "\n",
    "parquet_files = glob.glob('tag_data/**/*.parquet', recursive=True)\n",
    "print(f\"Total Parquet files: {len(parquet_files)}\")\n",
    "print(f\"\\nSample files:\")\n",
    "for f in parquet_files[:5]:\n",
    "    print(f\"  {f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all data into a DataFrame\n",
    "query = \"\"\"\n",
    "SELECT \n",
    "    tag_id,\n",
    "    name,\n",
    "    datetime,\n",
    "    timestamp_ms,\n",
    "    latitude,\n",
    "    longitude,\n",
    "    accuracy,\n",
    "    battery,\n",
    "    is_inaccurate,\n",
    "    location_hash,\n",
    "    year,\n",
    "    month,\n",
    "    day\n",
    "FROM 'tag_data/**/*.parquet'\n",
    "ORDER BY tag_id, timestamp_ms DESC\n",
    "\"\"\"\n",
    "\n",
    "df = conn.execute(query).df()\n",
    "print(f\"Total records: {len(df)}\")\n",
    "print(f\"Unique tags: {df['tag_id'].nunique()}\")\n",
    "print(f\"Date range: {df['datetime'].min()} to {df['datetime'].max()}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Statistics Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overall statistics\n",
    "stats_query = \"\"\"\n",
    "SELECT \n",
    "    COUNT(DISTINCT tag_id) as total_tags,\n",
    "    COUNT(*) as total_records,\n",
    "    COUNT(DISTINCT location_hash) as unique_locations,\n",
    "    ROUND(AVG(accuracy), 2) as avg_accuracy_m,\n",
    "    ROUND(MIN(accuracy), 2) as min_accuracy_m,\n",
    "    ROUND(MAX(accuracy), 2) as max_accuracy_m,\n",
    "    COUNT(DISTINCT DATE(datetime)) as unique_days\n",
    "FROM 'tag_data/**/*.parquet'\n",
    "\"\"\"\n",
    "\n",
    "stats = conn.execute(stats_query).df()\n",
    "stats.T.rename(columns={0: 'Value'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Per-tag statistics\n",
    "tag_stats_query = \"\"\"\n",
    "SELECT \n",
    "    tag_id,\n",
    "    name,\n",
    "    COUNT(*) as records,\n",
    "    MIN(datetime) as first_seen,\n",
    "    MAX(datetime) as last_seen,\n",
    "    ROUND(AVG(accuracy), 2) as avg_accuracy_m,\n",
    "    SUM(CASE WHEN is_inaccurate THEN 1 ELSE 0 END) as inaccurate_count,\n",
    "    MAX(battery) as last_battery\n",
    "FROM 'tag_data/**/*.parquet'\n",
    "GROUP BY tag_id, name\n",
    "ORDER BY tag_id\n",
    "\"\"\"\n",
    "\n",
    "tag_stats = conn.execute(tag_stats_query).df()\n",
    "tag_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Histogram of accuracy\n",
    "axes[0].hist(df['accuracy'], bins=20, edgecolor='black', alpha=0.7)\n",
    "axes[0].set_xlabel('Accuracy (meters)')\n",
    "axes[0].set_ylabel('Count')\n",
    "axes[0].set_title('Distribution of Location Accuracy')\n",
    "axes[0].axvline(df['accuracy'].mean(), color='red', linestyle='--', label=f'Mean: {df[\"accuracy\"].mean():.2f}m')\n",
    "axes[0].legend()\n",
    "\n",
    "# Box plot by tag\n",
    "df.boxplot(column='accuracy', by='tag_id', ax=axes[1], grid=False)\n",
    "axes[1].set_xlabel('Tag ID')\n",
    "axes[1].set_ylabel('Accuracy (meters)')\n",
    "axes[1].set_title('Accuracy Distribution by Tag')\n",
    "plt.suptitle('')  # Remove default title\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time-based analysis\n",
    "time_query = \"\"\"\n",
    "SELECT \n",
    "    strftime(datetime, '%H') as hour,\n",
    "    COUNT(*) as count,\n",
    "    COUNT(DISTINCT tag_id) as unique_tags\n",
    "FROM 'tag_data/**/*.parquet'\n",
    "GROUP BY hour\n",
    "ORDER BY hour\n",
    "\"\"\"\n",
    "\n",
    "time_df = conn.execute(time_query).df()\n",
    "\n",
    "if not time_df.empty:\n",
    "    fig, ax = plt.subplots(figsize=(10, 5))\n",
    "    ax.bar(time_df['hour'], time_df['count'], color='skyblue', edgecolor='black')\n",
    "    ax.set_xlabel('Hour of Day')\n",
    "    ax.set_ylabel('Number of Location Records')\n",
    "    ax.set_title('Location Updates by Hour of Day')\n",
    "    ax.grid(axis='y', alpha=0.3)\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Not enough time-based data for hourly analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Geographic visualization\n",
    "import folium\n",
    "from folium import plugins\n",
    "\n",
    "# Create a map centered on the mean location\n",
    "center_lat = df['latitude'].mean()\n",
    "center_lon = df['longitude'].mean()\n",
    "\n",
    "m = folium.Map(location=[center_lat, center_lon], zoom_start=15)\n",
    "\n",
    "# Add markers for each tag's latest location\n",
    "latest_locations = df.loc[df.groupby('tag_id')['timestamp_ms'].idxmax()]\n",
    "\n",
    "for _, row in latest_locations.iterrows():\n",
    "    folium.CircleMarker(\n",
    "        location=[row['latitude'], row['longitude']],\n",
    "        radius=5,\n",
    "        popup=f\"{row['name']}<br>Accuracy: {row['accuracy']:.2f}m<br>{row['datetime']}\",\n",
    "        tooltip=row['name'],\n",
    "        color='blue',\n",
    "        fill=True,\n",
    "        fillColor='lightblue'\n",
    "    ).add_to(m)\n",
    "\n",
    "# Add a heatmap of all locations\n",
    "heat_data = [[row['latitude'], row['longitude']] for idx, row in df.iterrows()]\n",
    "plugins.HeatMap(heat_data, radius=15).add_to(m)\n",
    "\n",
    "print(f\"Map centered at: {center_lat:.6f}, {center_lon:.6f}\")\n",
    "print(f\"Showing {len(latest_locations)} tags on the map\")\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Quality Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data quality metrics\n",
    "quality_query = \"\"\"\n",
    "SELECT \n",
    "    'Battery Status' as metric,\n",
    "    CAST(battery AS VARCHAR) as value,\n",
    "    COUNT(*) as count,\n",
    "    ROUND(COUNT(*) * 100.0 / SUM(COUNT(*)) OVER(), 2) as percentage\n",
    "FROM 'tag_data/**/*.parquet'\n",
    "GROUP BY battery\n",
    "UNION ALL\n",
    "SELECT \n",
    "    'Accuracy Status' as metric,\n",
    "    CASE WHEN is_inaccurate THEN 'Inaccurate' ELSE 'Accurate' END as value,\n",
    "    COUNT(*) as count,\n",
    "    ROUND(COUNT(*) * 100.0 / SUM(COUNT(*)) OVER(), 2) as percentage\n",
    "FROM 'tag_data/**/*.parquet'\n",
    "GROUP BY is_inaccurate\n",
    "UNION ALL\n",
    "SELECT \n",
    "    'Accuracy Range' as metric,\n",
    "    CASE \n",
    "        WHEN accuracy < 10 THEN '< 10m'\n",
    "        WHEN accuracy < 20 THEN '10-20m'\n",
    "        WHEN accuracy < 30 THEN '20-30m'\n",
    "        WHEN accuracy < 50 THEN '30-50m'\n",
    "        ELSE '50m+'\n",
    "    END as value,\n",
    "    COUNT(*) as count,\n",
    "    ROUND(COUNT(*) * 100.0 / SUM(COUNT(*)) OVER(), 2) as percentage\n",
    "FROM 'tag_data/**/*.parquet'\n",
    "GROUP BY \n",
    "    CASE \n",
    "        WHEN accuracy < 10 THEN '< 10m'\n",
    "        WHEN accuracy < 20 THEN '10-20m'\n",
    "        WHEN accuracy < 30 THEN '20-30m'\n",
    "        WHEN accuracy < 50 THEN '30-50m'\n",
    "        ELSE '50m+'\n",
    "    END\n",
    "ORDER BY metric, value\n",
    "\"\"\"\n",
    "\n",
    "quality_df = conn.execute(quality_query).df()\n",
    "quality_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize quality metrics\n",
    "metrics = quality_df['metric'].unique()\n",
    "fig, axes = plt.subplots(1, len(metrics), figsize=(15, 4))\n",
    "\n",
    "for i, metric in enumerate(metrics):\n",
    "    metric_data = quality_df[quality_df['metric'] == metric]\n",
    "    ax = axes[i] if len(metrics) > 1 else axes\n",
    "    \n",
    "    ax.pie(metric_data['count'], \n",
    "           labels=metric_data['value'], \n",
    "           autopct='%1.1f%%',\n",
    "           startangle=90)\n",
    "    ax.set_title(metric)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Partition Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze partition structure\n",
    "partition_query = \"\"\"\n",
    "SELECT \n",
    "    year,\n",
    "    month,\n",
    "    day,\n",
    "    COUNT(DISTINCT tag_id) as tags,\n",
    "    COUNT(*) as records,\n",
    "    ROUND(AVG(accuracy), 2) as avg_accuracy\n",
    "FROM 'tag_data/**/*.parquet'\n",
    "GROUP BY year, month, day\n",
    "ORDER BY year, month, day\n",
    "\"\"\"\n",
    "\n",
    "partitions = conn.execute(partition_query).df()\n",
    "print(\"Partition Summary:\")\n",
    "partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File size analysis\n",
    "import os\n",
    "\n",
    "file_sizes = []\n",
    "for file in parquet_files:\n",
    "    size = os.path.getsize(file)\n",
    "    parts = file.split('/')\n",
    "    tag_id = int(parts[1].split('=')[1]) if 'tag_id=' in parts[1] else None\n",
    "    file_sizes.append({\n",
    "        'file': file,\n",
    "        'tag_id': tag_id,\n",
    "        'size_kb': size / 1024\n",
    "    })\n",
    "\n",
    "size_df = pd.DataFrame(file_sizes)\n",
    "print(f\"Total storage: {size_df['size_kb'].sum():.2f} KB\")\n",
    "print(f\"Average file size: {size_df['size_kb'].mean():.2f} KB\")\n",
    "print(f\"\\nSize by tag:\")\n",
    "size_df.groupby('tag_id')['size_kb'].sum().sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Custom Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find tags with most movement (highest location variance)\n",
    "movement_query = \"\"\"\n",
    "SELECT \n",
    "    tag_id,\n",
    "    name,\n",
    "    COUNT(*) as locations,\n",
    "    ROUND(STDDEV(latitude) * 111000, 2) as lat_variance_m,\n",
    "    ROUND(STDDEV(longitude) * 111000, 2) as lon_variance_m,\n",
    "    ROUND(MAX(latitude) - MIN(latitude), 6) as lat_range,\n",
    "    ROUND(MAX(longitude) - MIN(longitude), 6) as lon_range\n",
    "FROM 'tag_data/**/*.parquet'\n",
    "GROUP BY tag_id, name\n",
    "HAVING COUNT(*) > 0\n",
    "ORDER BY (lat_variance_m + lon_variance_m) DESC\n",
    "LIMIT 10\n",
    "\"\"\"\n",
    "\n",
    "movement = conn.execute(movement_query).df()\n",
    "print(\"Tags with most movement variance:\")\n",
    "movement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query specific tag history\n",
    "tag_to_query = 1  # Change this to query different tags\n",
    "\n",
    "tag_history_query = f\"\"\"\n",
    "SELECT \n",
    "    datetime,\n",
    "    latitude,\n",
    "    longitude,\n",
    "    accuracy,\n",
    "    battery,\n",
    "    is_inaccurate\n",
    "FROM 'tag_data/tag_id={tag_to_query}/**/*.parquet'\n",
    "ORDER BY timestamp_ms DESC\n",
    "LIMIT 10\n",
    "\"\"\"\n",
    "\n",
    "tag_history = conn.execute(tag_history_query).df()\n",
    "print(f\"Recent history for Tag {tag_to_query}:\")\n",
    "tag_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close DuckDB connection\n",
    "conn.close()\n",
    "print(\"Analysis complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}